---
phase: 03-image-to-image-editing
plan: 02
type: execute
wave: 2
depends_on:
  - "03-01"
files_modified:
  - src/app/page.tsx
  - src/app/api/generate/route.ts
  - src/components/result-display.tsx
autonomous: true
requirements:
  - GEN-02
  - OUT-05

must_haves:
  truths:
    - "User can upload a reference image and type an edit prompt to generate a transformed image"
    - "User can paste an image from clipboard (Cmd+V / Ctrl+V) and it appears in the upload zone as the reference image"
    - "The app auto-detects image-to-image mode when a reference image is present (no manual mode toggle)"
    - "After image-to-image generation, user sees the original reference as a small thumbnail above the full-size result"
    - "Removing the uploaded image returns the app to text-to-image mode"
  artifacts:
    - path: "src/app/page.tsx"
      provides: "Image state management, contextual mode detection, API call with image, clipboard paste handler"
      contains: "uploadedImage"
    - path: "src/app/api/generate/route.ts"
      provides: "Image-to-image generation via Gemini inlineData"
      contains: "inlineData"
    - path: "src/components/result-display.tsx"
      provides: "Before/after display for image-to-image results"
      contains: "originalImage"
  key_links:
    - from: "src/app/page.tsx"
      to: "src/components/image-upload.tsx"
      via: "renders ImageUpload, passes uploadedImage state and handlers"
      pattern: "<ImageUpload"
    - from: "src/app/page.tsx"
      to: "src/app/api/generate/route.ts"
      via: "fetch POST /api/generate with image and imageMimeType fields"
      pattern: "fetch.*api/generate"
    - from: "src/app/api/generate/route.ts"
      to: "@google/genai"
      via: "generateContent with inlineData parts array"
      pattern: "inlineData"
    - from: "src/app/page.tsx"
      to: "src/components/result-display.tsx"
      via: "passes originalImage prop for before/after display"
      pattern: "originalImage"
---

<objective>
Wire the image upload component into the main page, extend the API route for image-to-image generation, add clipboard paste support, and build the before/after result display.

Purpose: Connects the upload component (Plan 03-01) to the generation pipeline, completing the image-to-image editing flow end-to-end. Clipboard paste provides a fast alternative to file picker/drag-and-drop. The before/after display gives users context to evaluate the transformation.

Output: A complete image-to-image editing flow: upload/paste a reference image, type an edit prompt, generate, see before/after result.
</objective>

<execution_context>
@/Users/nusretozturk/.claude/get-shit-done/workflows/execute-plan.md
@/Users/nusretozturk/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-image-to-image-editing/03-RESEARCH.md
@.planning/phases/03-image-to-image-editing/03-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Wire image upload into page, extend API route for image-to-image, and add clipboard paste</name>
  <files>src/app/page.tsx, src/app/api/generate/route.ts</files>
  <action>
  **In `src/app/page.tsx`** -- modify the existing page component (from Phase 2):

  1. **Add image state:**
     ```typescript
     const [uploadedImage, setUploadedImage] = useState<ImageUploadState | null>(null);
     const [uploadError, setUploadError] = useState<string | null>(null);
     ```
     Import `ImageUploadState` from `@/lib/types`.

  2. **Contextual mode detection (derived, not stored):**
     ```typescript
     const isImageToImage = uploadedImage !== null;
     ```
     No mode selector component. No tabs. No toggle. The presence of an uploaded image IS the mode.

  3. **Render ImageUpload component** above the prompt textarea:
     ```tsx
     <ImageUpload
       onImageSelect={(image) => {
         setUploadedImage(image);
         setUploadError(null);
       }}
       onImageRemove={() => {
         setUploadedImage(null);
         setUploadError(null);
       }}
       onError={(msg) => setUploadError(msg)}
       uploadedImage={uploadedImage}
       disabled={isLoading}  // Use whatever loading state name exists from Phase 2
     />
     ```
     Show `uploadError` as an inline error message below the upload zone (red text, small font) when non-null. Clear it on successful upload or removal.

  4. **Add clipboard paste handler** at the page level (NOT in ImageUpload component):
     ```typescript
     useEffect(() => {
       const handlePaste = (e: ClipboardEvent) => {
         const items = e.clipboardData?.items;
         if (!items) return;

         for (const item of Array.from(items)) {
           if (item.type.startsWith("image/")) {
             e.preventDefault();
             const file = item.getAsFile();
             if (file) {
               // Import processFile logic or extract to a shared util
               // Validate -> resize -> read -> setUploadedImage
               processImageFile(file);
             }
             return;
           }
         }
         // If no image found, let the event propagate (user pasting text into prompt)
       };

       document.addEventListener("paste", handlePaste);
       return () => document.removeEventListener("paste", handlePaste);
     }, []);  // Include necessary deps
     ```
     Extract a `processImageFile` function that mirrors ImageUpload's `processFile` pipeline (validate -> resize -> readAsDataUrl -> setUploadedImage). Import `validateImageFile`, `resizeImageIfNeeded`, `readFileAsDataUrl` from `@/lib/image-utils`.

     **Critical:** Only call `e.preventDefault()` when an image is found in the clipboard. If the clipboard contains only text, let the event propagate so the prompt textarea receives it normally.

  5. **Update the generation request** in the existing `handleGenerate` (or equivalent) function:
     ```typescript
     const body: Record<string, unknown> = {
       prompt,
       aspectRatio,
       resolution,
       mode: isImageToImage ? "image-to-image" : "text-to-image",
     };

     if (uploadedImage) {
       body.image = uploadedImage.dataUrl;
       body.imageMimeType = uploadedImage.mimeType;
     }
     ```
     The rest of the fetch call and response handling stays the same as Phase 2.

  6. **Track original image for before/after display:**
     When generation starts with an uploaded image, store the reference image data URL in a variable (e.g., `originalImageForDisplay`) that persists into the result display. After generation completes, pass it to the result display component.
     ```typescript
     const [originalImage, setOriginalImage] = useState<string | null>(null);
     ```
     In `handleGenerate`: if `isImageToImage`, set `setOriginalImage(uploadedImage.dataUrl)` before starting the request.
     After successful generation: keep `originalImage` set so result-display can show it.
     When user resets/starts new generation: clear `originalImage`.

  **In `src/app/api/generate/route.ts`** -- extend the existing route handler:

  1. **Parse the optional image fields from the request body:**
     The Zod schema from Phase 1 should already include `image` (optional string) and `imageMimeType` (optional enum). If not, add them:
     ```typescript
     image: z.string().optional(),
     imageMimeType: z.enum(["image/jpeg", "image/png", "image/webp"]).optional(),
     ```
     Add a refinement: if `mode === "image-to-image"`, `image` must be present.

  2. **Build the Gemini contents array conditionally:**
     ```typescript
     const parts: Part[] = [];
     parts.push({ text: prompt });

     if (image && mode === "image-to-image") {
       // Strip "data:image/png;base64," prefix to get raw base64
       const base64Data = image.includes(",") ? image.split(",")[1] : image;
       const mimeType = imageMimeType || "image/jpeg";
       parts.push({
         inlineData: {
           data: base64Data,
           mimeType,
         },
       });
     }
     ```

  3. **Pass parts to `generateContent`:**
     ```typescript
     const response = await ai.models.generateContent({
       model: MODEL_ID,
       contents: [{ role: "user", parts }],
       config: { /* existing config from Phase 1/2 */ },
     });
     ```
     The rest of the response handling (extracting image from response, error handling, safety filter detection) stays the same as Phase 1/2.

  4. **Do NOT change the response format.** The route already returns binary image data for success and JSON for errors (from Phase 1). Image-to-image uses the same response format.
  </action>
  <verify>
  - `src/app/page.tsx` contains `uploadedImage` state, `ImageUpload` component render, clipboard paste handler with `document.addEventListener("paste", ...)`, and conditional `body.image` in the fetch call.
  - `src/app/api/generate/route.ts` contains `inlineData` in the parts array for image-to-image mode.
  - `npx tsc --noEmit` passes with no type errors.
  - The paste handler only calls `e.preventDefault()` when clipboard contains an image (does not block text paste into prompt).
  </verify>
  <done>
  The page renders the ImageUpload component, manages image state, detects image-to-image mode contextually, sends the reference image in the API request, and handles clipboard paste at the document level. The API route builds a Gemini contents array with text + inlineData parts for image-to-image, or text-only for text-to-image.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add before/after result display for image-to-image mode</name>
  <files>src/components/result-display.tsx</files>
  <action>
  Modify the existing `result-display.tsx` (from Phase 2) to support before/after display for image-to-image results.

  1. **Add `originalImage` prop:**
     ```typescript
     interface ResultDisplayProps {
       // ... existing props from Phase 2 (imageUrl, isLoading, error, etc.)
       originalImage?: string | null;  // Data URL of the reference image for before/after
     }
     ```

  2. **Render before/after when `originalImage` is provided:**
     When `originalImage` is set and a generated image exists:
     - Show a small "Original" section above the main generated image:
       - Small thumbnail (120-160px width, aspect ratio preserved) with `object-contain` or `object-cover`.
       - Label text "Original" in small, muted text above or beside the thumbnail.
       - The thumbnail uses the `originalImage` data URL as `src`.
     - The generated image remains the hero element (large, prominent) -- do NOT reduce its size.
     - Layout: vertical stack. Original thumbnail at top (left-aligned), generated result below (full width).

  3. **When `originalImage` is null or undefined (text-to-image mode):**
     - Render exactly as before (Phase 2 behavior). No before/after section.
     - This ensures backward compatibility with text-to-image flow.

  4. **Styling (Tailwind):**
     - Original thumbnail: `w-32 h-auto rounded-md border` (subtle border to distinguish from background).
     - "Original" label: `text-xs text-gray-500 mb-1` (or equivalent muted style from existing theme).
     - Container for the original section: `mb-4` spacing before the generated result.
     - Use existing component patterns from Phase 2 for consistency.

  5. **Do NOT add:**
     - Slider/overlay comparison interaction (too complex for v1).
     - Side-by-side layout (halves image size on mobile).
     - Any new interactivity beyond displaying the images.
  </action>
  <verify>
  - `src/components/result-display.tsx` accepts an optional `originalImage` prop.
  - When `originalImage` is provided with a generated image, both are rendered (small original above, large generated below).
  - When `originalImage` is null, the component renders identically to Phase 2.
  - `npx tsc --noEmit` passes with no type errors.
  </verify>
  <done>
  The result display shows a compact "Original" thumbnail above the hero generated image when in image-to-image mode. Text-to-image mode renders unchanged. The generated image remains the dominant visual element.
  </done>
</task>

</tasks>

<verification>
1. End-to-end flow: ImageUpload component is rendered in page.tsx, accepts images via file picker and drag-and-drop, clipboard paste works at document level, the API request includes image data for image-to-image mode, and the result display shows before/after.
2. The API route builds `inlineData` parts for image-to-image and text-only parts for text-to-image.
3. Clipboard paste only intercepts image content; text paste into the prompt textarea works normally.
4. Mode is contextually detected (no explicit toggle/tabs).
5. `npx tsc --noEmit` passes across all modified files.
6. Text-to-image flow (from Phase 2) still works unchanged when no image is uploaded.
</verification>

<success_criteria>
- User can upload a reference image via any of the three input methods (file picker, drag-and-drop, clipboard paste), type an edit prompt, and generate a transformed image.
- After image-to-image generation, the original reference image appears as a small thumbnail above the full-size result.
- Removing the uploaded image returns the app to text-to-image mode seamlessly.
- Pasting text into the prompt textarea does not trigger image upload behavior.
- The existing text-to-image flow is unaffected when no image is uploaded.
</success_criteria>

<output>
After completion, create `.planning/phases/03-image-to-image-editing/03-02-SUMMARY.md`
</output>
